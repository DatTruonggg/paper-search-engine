# Asta vs Human Search: Performance Analysis

**Task:** Find papers about LLM context length limitations

---

## Key Findings

| Metric | Asta | Human | Winner |
|--------|------|-------|--------|
| **Relevance** | 27.8% (5/18) | 100% (10/10) | Human |
| **Time** | ~3.5 min | ~4 min | Tie |
| **Coverage** | 5 techniques | 90+ techniques | Human |
| **Sources** | Semantic Scholar only | Multi-source | Human |

---

## Search Results Comparison

### Asta Results (18 Papers)
- **5 relevant papers** (27.8%)
- **13 irrelevant papers** (72.2%)
- **Top result wrong**: "Incremental Learning" instead of context length

### Human Results (10 Papers)
- **10 relevant papers** (100%)
- **4 comprehensive surveys**
- **6 specific technique papers**
- **All directly address the question**

---

## Why Asta Failed

### 1. **Semantic Drift**
- Reranker confused "learning over time" with "processing long sequences"
- No keyword filtering to enforce topical relevance

### 2. **No Survey Bias**
- Treats surveys same as individual papers
- Missed the most valuable comprehensive surveys

### 3. **Quote Extraction Issues**
- Only 26.3% of papers got meaningful quotes
- Many papers returned empty quotes

### 4. **Single Source Limitation**
- Only searches Semantic Scholar
- No access to Medium, GitHub, or industry blogs

---

## Why Human Succeeded

### 1. **Survey-First Strategy**
- Found 4 comprehensive surveys first
- Extracted 90+ techniques systematically
- Organized knowledge landscape

### 2. **Multi-Source Approach**
- **ArXiv**: Research papers
- **Medium**: Practical guides  
- **GitHub**: Curated awesome-lists
- **Blogs**: Industry perspectives

### 3. **Iterative Refinement**
- Changed query when no results
- Built each iteration on previous
- Fast adaptation (seconds, not minutes)

### 4. **Validation During Search**
- Checked abstracts before counting
- Ensured relevance before diving deep
- No wasted time on irrelevant papers

---

## Techniques Extracted (90+ Total)

### From 4 Major Surveys:

#### **Length Extrapolation (12 techniques)**
- RoPE, ALiBi, xPOS, YaRN
- Positional Interpolation (PI)
- StreamingLLM

#### **Attention Approximation (15 techniques)**
- LED, Linformer, Performer
- Longformer, Reformer
- FlashAttention (v1, v2, v3)

#### **Attention-free Transformers (8 techniques)**
- S4, Mamba, Hyena
- H3, AFT, MEGA

#### **Model Compression (7 techniques)**
- LLM.int8(), GPTQ, AWQ
- SmoothQuant, LLM-Pruner

#### **Hardware-aware (6 techniques)**
- Ring Attention, PagedAttention
- Infinite-LLM

#### **Memory Management (5 techniques)**
- Memory Bank, MemGPT
- KV Cache Optimization

#### **Reasoning Strategies (8 techniques)**
- Chain-of-Thought, Long CoT
- Self-reflection, React

#### **Tool Integration (4 techniques)**
- Toolformer, Tool-augmented reasoning

#### **RAG & Retrieval (8 techniques)**
- RAG, LongRAG, RAPTOR
- AttentionRAG, Hybrid search

#### **Practical Strategies (6 techniques)**
- Chunking (~1,800 chars optimal)
- Recursive chunking, Summarization

---

## ðŸ› ï¸ Recommended Improvements for Asta

### **High Priority (Immediate)**

1. **Survey Detection & Boosting**
   ```python
   def is_survey_paper(title: str) -> bool:
       return any(kw in title.lower() for kw in ['survey', 'review', 'overview'])
   
   def boost_surveys(papers: List[Paper]) -> List[Paper]:
       surveys = [p for p in papers if is_survey_paper(p.title)]
       return surveys + [p for p in papers if not is_survey_paper(p.title)]
   ```

2. **Hard Keyword Filtering**
   ```python
   def filter_by_keywords(papers: List[Paper], keywords: List[str]) -> List[Paper]:
       return [p for p in papers if any(kw in (p.title + p.abstract).lower() for kw in keywords)]
   ```

3. **Multi-Source Integration**
   - Add Google search for Medium articles
   - Add GitHub awesome-list parsing
   - Add industry blog search

4. **Interactive Query Refinement**
   - Show rewritten query to user
   - Allow modification before search
   - Enable mid-search pivoting

5. **Better Quote Extraction**
   - Fallback to abstract if no quotes
   - Use introduction if abstract weak
   - Never return empty quotes

### **Medium Priority**

6. **Context-Aware Reranking**
   - Boost papers with exact keyword matches
   - Penalize semantic drift
   - Consider citation count and recency

7. **Source Type Awareness**
   - Prioritize surveys for landscape questions
   - Prioritize recent papers for specific techniques
   - Balance academic vs practical sources

---

## Human Search Best Practices

### **For Research Questions:**

1. **Extract Keywords**
   - Main topic + year + "survey"
   - Example: "context length limitation LLM survey 2024"

2. **Search Surveys First**
   - Google Scholar: `"{topic} survey {year}"`
   - ArXiv: `"survey {topic}"`

3. **Read Survey Abstracts**
   - Validate relevance quickly
   - Check if SOTA techniques covered

4. **Extract Techniques from Surveys**
   - Note technique names and citations
   - Build comprehensive taxonomy

5. **Search for Specific Papers**
   - Use technique names from surveys
   - Target recent work (2024-2025)

6. **Search Alternative Sources**
   - Medium for practical guides
   - GitHub for curated lists
   - YouTube for explanations

7. **Validate All Results**
   - Check each paper's abstract
   - Ensure topical relevance
   - Discard false positives

---

## Exact Search Queries That Work

### **Medium Articles**
```
site:medium.com context length limitation LLM 2024
site:medium.com "long context window" techniques
site:medium.com infinite context language models
```

### **GitHub Repositories**
```
site:github.com awesome long context LLM
site:github.com awesome efficient LLM
site:github.com awesome context engineering
```

### **Research Blogs**
```
site:research.ibm.com context length
site:databricks.com long context RAG
"context length" LLM blog 2024
```

### **Survey Papers**
```
site:arxiv.org intitle:survey "context length" 2024
site:arxiv.org "survey" "long context" LLM
"context length extension" survey arxiv
```

### **Recent Papers**
```
site:arxiv.org "long context" LLM 2024
site:arxiv.org "context length" 2025
site:arxiv.org infinite context reasoning
```

---

## Google Search Operators Guide

| Operator | Example | Purpose |
|----------|---------|---------|
| `site:` | `site:medium.com LLM` | Search specific site only |
| `"phrase"` | `"context length"` | Exact phrase match |
| `intitle:` | `intitle:survey` | Word in title |
| `inurl:` | `inurl:awesome` | Word in URL |
| `filetype:` | `filetype:pdf` | Specific file type |
| `-word` | `LLM -GPT` | Exclude term |
| `OR` | `LLM OR GPT` | Either term |
| `2020..2024` | `2020..2024` | Date range |

### **Progressive Search Strategy:**
1. Start broad: `long context LLM`
2. Add exact phrases: `"long context" LLM handling`
3. Target source: `site:medium.com "long context" LLM`
4. Add recency: `site:medium.com "long context" LLM 2024`
5. Add specificity: `site:medium.com "context length limitation" LLM "handling techniques" 2024`

---

## Performance Benchmarks

### **Search Quality**
- **Human**: 100% precision, comprehensive coverage
- **Asta**: 27.8% precision, limited scope

### **Time Efficiency**
- **Human**: ~4 minutes (including validation)
- **Asta**: ~3.5 minutes (but low quality results)

### **Coverage**
- **Human**: 90+ techniques from multiple sources
- **Asta**: 5 techniques from single source

### **Source Diversity**
- **Human**: Academic + Practical + Industry
- **Asta**: Academic only

---

## Conclusion & Recommendations

### **Current State**
- **Asta**: Fast but inaccurate, single-source, no survey awareness
- **Human**: Slower but comprehensive, multi-source, survey-first

### **Optimal Workflow**
1. **Use Human search** for:
   - Initial landscape exploration
   - Finding survey papers
   - Comprehensive technique extraction

2. **Use Asta** (after improvements) for:
   - Scaling up similar papers
   - Quote extraction from known-good papers
   - Citation following

### **Bottom Line**
**Human search is significantly better** for research questions requiring:
- High precision
- Comprehensive coverage
- Multi-source perspectives
- Survey-based landscape understanding

**Asta needs major improvements** in topical relevance, document type awareness, and multi-source integration before it can match human research capabilities.
