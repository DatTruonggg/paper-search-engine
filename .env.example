# =============================================================================
# PAPER SEARCH ENGINE - ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and update the values according to your setup
# 
# IMPORTANT: Never commit the actual .env file to version control!
# =============================================================================

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
API_HOST=0.0.0.0
API_PORT=8000
DEBUG_MODE=true

# =============================================================================
# ELASTICSEARCH CONFIGURATION
# =============================================================================
# Elasticsearch server endpoint
ES_HOST=http://103.3.247.120:9202
# Elasticsearch index name for papers
ES_INDEX_NAME=papers

# =============================================================================
# MINIO OBJECT STORAGE CONFIGURATION
# =============================================================================
# MinIO server endpoint
MINIO_ENDPOINT=http://103.3.247.120:9002
# MinIO access credentials (default for development)
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
# MinIO bucket name for papers
MINIO_BUCKET=papers

# =============================================================================
# BGE EMBEDDING MODEL CONFIGURATION
# =============================================================================
# BGE model name for embeddings
BGE_MODEL_NAME=BAAI/bge-large-en-v1.5
# Directory to cache BGE model files
BGE_CACHE_DIR=./models

# =============================================================================
# SEARCH CONFIGURATION
# =============================================================================
# Maximum number of search results to return
MAX_SEARCH_RESULTS=20
# Default search mode: hybrid, semantic, bm25, title_only
DEFAULT_SEARCH_MODE=hybrid

# =============================================================================
# DOCUMENT PROCESSING CONFIGURATION
# =============================================================================
# Chunk size for document processing (tokens)
CHUNK_SIZE=300
# Overlap between chunks (tokens)
CHUNK_OVERLAP=50

# =============================================================================
# DATA PATHS
# =============================================================================
# Path to processed markdown files
MARKDOWN_DATA_PATH=./data/processed/markdown
# Path to JSON metadata files
JSON_METADATA_PATH=./data/pdfs
# Local directory for PDF files
PDF_LOCAL_DIR=./data/pdfs

# =============================================================================
# LLM API KEYS (REQUIRED)
# =============================================================================
# OpenAI API key for GPT models
OPENAI_API_KEY=your_openai_api_key_here
# Google API key for Gemini models
GOOGLE_API_KEY=your_google_api_key_here

# =============================================================================
# LLM MODEL CONFIGURATION
# =============================================================================
# Default LLM provider: openai, google
DEFAULT_LLM_PROVIDER=openai
# OpenAI model names
OPENAI_MODEL=gpt-4o
OPENAI_MINI_MODEL=gpt-4o-mini
# Google model name
GOOGLE_MODEL=gemini-1.5-pro

# =============================================================================
# LLAMA AGENT CONFIGURATION
# =============================================================================
# Maximum search iterations for LlamaIndex agent
LLAMA_AGENT_MAX_ITERATIONS=3
# Maximum results per search query
LLAMA_AGENT_MAX_RESULTS_PER_SEARCH=20
# Minimum relevance score threshold
LLAMA_AGENT_MIN_RELEVANCE_SCORE=0.5
# Default search mode for LlamaIndex agent
LLAMA_AGENT_DEFAULT_SEARCH_MODE=hybrid
# Enable query analysis
LLAMA_AGENT_ENABLE_QUERY_ANALYSIS=true
# Enable result reranking
LLAMA_AGENT_ENABLE_RESULT_RERANKING=true
# Maximum papers in response
LLAMA_AGENT_RESPONSE_MAX_PAPERS=10
# Include explanations in responses
LLAMA_AGENT_INCLUDE_EXPLANATIONS=true
# Include summaries in responses
LLAMA_AGENT_INCLUDE_SUMMARIES=true
# Search timeout in seconds
LLAMA_AGENT_SEARCH_TIMEOUT=30
# LLM call timeout in seconds
LLAMA_AGENT_LLM_TIMEOUT=20
# Enable verbose logging for LlamaIndex agent
LLAMA_AGENT_VERBOSE=false

# =============================================================================
# QA AGENT CONFIGURATION
# =============================================================================
# Default LLM provider for QA agent
QA_AGENT_DEFAULT_LLM_PROVIDER=openai
# Maximum tokens for LLM responses
QA_AGENT_MAX_TOKENS=4000
# LLM temperature (0.0 to 1.0)
QA_AGENT_TEMPERATURE=0.1
# Maximum QA iterations
QA_AGENT_MAX_ITERATIONS=5
# Enable verbose logging for QA agent
QA_AGENT_VERBOSE=true
# Maximum context chunks per query
QA_AGENT_MAX_CONTEXT_CHUNKS=10
# Chunk overlap for context
QA_AGENT_CHUNK_OVERLAP=2
# Enable result reranking
QA_AGENT_RERANK_RESULTS=true
# Include image analysis
QA_AGENT_INCLUDE_IMAGES=true
# Timeout for operations in seconds
QA_AGENT_TIMEOUT_SECONDS=30
# Number of retry attempts
QA_AGENT_RETRY_ATTEMPTS=3
# Elasticsearch host for QA agent
QA_AGENT_ES_HOST=http://103.3.247.120:9202
# MinIO endpoint for QA agent
QA_AGENT_MINIO_ENDPOINT=http://103.3.247.120:9002
# MinIO bucket name for QA agent
QA_AGENT_MINIO_BUCKET=papers

# =============================================================================
# GENERAL AGENT BEHAVIOR SETTINGS
# =============================================================================
# Maximum tokens for agent responses
AGENT_MAX_TOKENS=4000
# Agent temperature (0.0 to 1.0)
AGENT_TEMPERATURE=0.1
# Maximum iterations for agent
AGENT_MAX_ITERATIONS=10
# Enable verbose logging for agents
AGENT_VERBOSE=true

# =============================================================================
# MEMORY AND CONTEXT SETTINGS
# =============================================================================
# Memory token limit for agents
AGENT_MEMORY_TOKEN_LIMIT=3000
# Context window size (number of past exchanges to keep)
AGENT_CONTEXT_WINDOW=5

# =============================================================================
# TOOL CONFIGURATION
# =============================================================================
# Enable web search functionality
ENABLE_WEB_SEARCH=true
# Maximum results for web search
WEB_SEARCH_MAX_RESULTS=5
# Maximum results for paper search
PAPER_SEARCH_MAX_RESULTS=20

# =============================================================================
# PERFORMANCE AND RELIABILITY SETTINGS
# =============================================================================
# LLM timeout in seconds
LLM_TIMEOUT_SECONDS=30
# Web search timeout in seconds
WEB_SEARCH_TIMEOUT_SECONDS=10
# Agent retry attempts
AGENT_RETRY_ATTEMPTS=3

# =============================================================================
# FEATURE FLAGS
# =============================================================================
# Enable tool caching
ENABLE_TOOL_CACHING=false
# Enable conversation persistence
ENABLE_CONVERSATION_PERSISTENCE=false

# =============================================================================
# DEVELOPMENT AND TESTING
# =============================================================================
# Set to true for development mode (enables debug logging)
# Set to false for production
DEBUG_MODE=true

# =============================================================================
# NOTES
# =============================================================================
# 1. Replace 'your_openai_api_key_here' and 'your_google_api_key_here' with actual API keys
# 2. Update server endpoints (ES_HOST, MINIO_ENDPOINT) to match your infrastructure
# 3. Adjust chunk sizes and timeouts based on your performance requirements
# 4. Set DEBUG_MODE=false for production deployments
# 5. Ensure all required services (Elasticsearch, MinIO) are running and accessible
# 6. The QA_AGENT_* variables override the general agent settings for QA-specific behavior
# 7. The LLAMA_AGENT_* variables override the general agent settings for LlamaIndex agent behavior
